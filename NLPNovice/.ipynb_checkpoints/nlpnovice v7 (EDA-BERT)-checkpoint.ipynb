{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from bert.tokenization.bert_tokenization import FullTokenizer\n",
    "\n",
    "# For Glove examples \n",
    "from scipy import spatial\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import nltk\n",
    "import unicodedata\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/davidkolb/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../../Data/NLPNovice/train.csv')\n",
    "test = pd.read_csv('../../Data/NLPNovice/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<bound method NDFrame.describe of          id keyword location  \\\n",
       " 0         1     NaN      NaN   \n",
       " 1         4     NaN      NaN   \n",
       " 2         5     NaN      NaN   \n",
       " 3         6     NaN      NaN   \n",
       " 4         7     NaN      NaN   \n",
       " ...     ...     ...      ...   \n",
       " 7608  10869     NaN      NaN   \n",
       " 7609  10870     NaN      NaN   \n",
       " 7610  10871     NaN      NaN   \n",
       " 7611  10872     NaN      NaN   \n",
       " 7612  10873     NaN      NaN   \n",
       " \n",
       "                                                    text  target  \n",
       " 0     Our Deeds are the Reason of this #earthquake M...       1  \n",
       " 1                Forest fire near La Ronge Sask. Canada       1  \n",
       " 2     All residents asked to 'shelter in place' are ...       1  \n",
       " 3     13,000 people receive #wildfires evacuation or...       1  \n",
       " 4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
       " ...                                                 ...     ...  \n",
       " 7608  Two giant cranes holding a bridge collapse int...       1  \n",
       " 7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
       " 7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
       " 7611  Police investigating after an e-bike collided ...       1  \n",
       " 7612  The Latest: More Homes Razed by Northern Calif...       1  \n",
       " \n",
       " [7613 rows x 5 columns]>,\n",
       " <bound method NDFrame.describe of          id keyword location  \\\n",
       " 0         0     NaN      NaN   \n",
       " 1         2     NaN      NaN   \n",
       " 2         3     NaN      NaN   \n",
       " 3         9     NaN      NaN   \n",
       " 4        11     NaN      NaN   \n",
       " ...     ...     ...      ...   \n",
       " 3258  10861     NaN      NaN   \n",
       " 3259  10865     NaN      NaN   \n",
       " 3260  10868     NaN      NaN   \n",
       " 3261  10874     NaN      NaN   \n",
       " 3262  10875     NaN      NaN   \n",
       " \n",
       "                                                    text  \n",
       " 0                    Just happened a terrible car crash  \n",
       " 1     Heard about #earthquake is different cities, s...  \n",
       " 2     there is a forest fire at spot pond, geese are...  \n",
       " 3              Apocalypse lighting. #Spokane #wildfires  \n",
       " 4         Typhoon Soudelor kills 28 in China and Taiwan  \n",
       " ...                                                 ...  \n",
       " 3258  EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...  \n",
       " 3259  Storm in RI worse than last hurricane. My city...  \n",
       " 3260  Green Line derailment in Chicago http://t.co/U...  \n",
       " 3261  MEG issues Hazardous Weather Outlook (HWO) htt...  \n",
       " 3262  #CityofCalgary has activated its Municipal Eme...  \n",
       " \n",
       " [3263 rows x 4 columns]>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe, test.describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_whitespace(data):\n",
    "    return data.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_URL(data):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'',data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html(data):\n",
    "    html=re.compile(r'<.*?>')\n",
    "    return html.sub(r'',data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(data):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accented_chars(data):\n",
    "    return unicodedata.normalize('NFKD', data).encode('ascii', 'ignore').decode('utf-8', 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(data):\n",
    "    table=str.maketrans('','',string.punctuation)\n",
    "    return data.translate(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_char(data):\n",
    "    new_data=''\n",
    "    for w in data:\n",
    "        print(w)\n",
    "        if len(w) > 1:\n",
    "            print(w)\n",
    "            new_data = new_data +  \" \" + w\n",
    "    \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(data, remove_digits=False):\n",
    "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
    "    data = re.sub(pattern, '', data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_lower_case(data):\n",
    "    return data.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenise(data):\n",
    "    data = word_tokenize(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(data):\n",
    "    filtered_sentence = [w for w in data if not w in stop_words] \n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(data):\n",
    "    data.apply(lambda x: [stemmer.stem(e) for e in x])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatise(data):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    data.apply(lambda x: [lemmatizer.lemmatize(e) for e in x])\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_clean(data):\n",
    "    data = remove_URL(data)\n",
    "    data = remove_html(data)\n",
    "    data = remove_emoji(data)\n",
    "    data = remove_whitespace(data)    \n",
    "    data = remove_accented_chars(data) \n",
    "    data = remove_special_characters(data)\n",
    "    data = remove_punctuation(data)\n",
    "    data = convert_lower_case(data)\n",
    "    return data\n",
    "    \n",
    "def nlp_tokenise(data):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    data = tokenise(data)\n",
    "    data = remove_stop_words(data)\n",
    "    return data\n",
    "     \n",
    "def nlp_normalise(data):\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    data = stemming(data)\n",
    "    data = lemmatise(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run preprossing steps to clean data\n",
    "train['text']=train['text'].apply(lambda x : nlp_clean(x))\n",
    "test['text']=test['text'].apply(lambda x : nlp_clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run steps to remove stop words\n",
    "train['text']=train['text'].apply(lambda x : nlp_tokenise(x))\n",
    "test['text']=test['text'].apply(lambda x : nlp_tokenise(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rejoin Data after tokenisation \n",
    "def combine_text(list_of_text):\n",
    "    combined_text = ''\n",
    "    for word in list_of_text:\n",
    "        combined_text = combined_text + ' ' + word\n",
    "    return combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text'] = train['text'].apply(lambda x : combine_text(x))\n",
    "test['text'] = test['text'].apply(lambda x : combine_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          deeds reason earthquake may allah forgive us\n",
       "1                 forest fire near la ronge sask canada\n",
       "2      residents asked shelter place notified office...\n",
       "3      13000 people receive wildfires evacuation ord...\n",
       "4      got sent photo ruby alaska smoke wildfires po...\n",
       "5      rockyfire update california hwy 20 closed dir...\n",
       "6      flood disaster heavy rain causes flash floodi...\n",
       "7                            im top hill see fire woods\n",
       "8      theres emergency evacuation happening buildin...\n",
       "9                         im afraid tornado coming area\n",
       "10                      three people died heat wave far\n",
       "11     haha south tampa getting flooded hah wait sec...\n",
       "12     raining flooding florida tampabay tampa 18 19...\n",
       "13                      flood bago myanmar arrived bago\n",
       "14        damage school bus 80 multi car crash breaking\n",
       "15                                            whats man\n",
       "16                                          love fruits\n",
       "17                                        summer lovely\n",
       "18                                             car fast\n",
       "19                                      goooooooaaaaaal\n",
       "20                                           ridiculous\n",
       "21                                          london cool\n",
       "22                                          love skiing\n",
       "23                                        wonderful day\n",
       "24                                             looooool\n",
       "25                                   wayi cant eat shit\n",
       "26                                        nyc last week\n",
       "27                                      love girlfriend\n",
       "28                                               cooool\n",
       "29                                           like pasta\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text'].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                           happened terrible car crash\n",
       "1      heard earthquake different cities stay safe e...\n",
       "2      forest fire spot pond geese fleeing across st...\n",
       "3                 apocalypse lighting spokane wildfires\n",
       "4                typhoon soudelor kills 28 china taiwan\n",
       "5                                 shakingits earthquake\n",
       "6      theyd probably still show life arsenal yester...\n",
       "7                                                   hey\n",
       "8                                              nice hat\n",
       "9                                                  fuck\n",
       "10                                       dont like cold\n",
       "11                                      nooooooooo dont\n",
       "12                                            dont tell\n",
       "13                                                     \n",
       "14                                              awesome\n",
       "15     birmingham wholesale market ablaze bbc news f...\n",
       "16               sunkxssedharry wear shorts race ablaze\n",
       "17     previouslyondoyintv toke makinwauas marriage ...\n",
       "18                                           check nsfw\n",
       "19     psa iuam splitting personalities techies foll...\n",
       "20            beware world ablaze sierra leone amp guap\n",
       "21              burning man ablaze turban diva via etsy\n",
       "22     diss song people take 1 thing run smh eye ope...\n",
       "23     rape victim dies sets ablaze 16yearold girl d...\n",
       "24                                       setting ablaze\n",
       "25     ctvtoronto bins front field house wer set abl...\n",
       "26     nowplaying alfons ablaze 2015 puls radio puls...\n",
       "27     burning rahm lets hope city hall builds giant...\n",
       "28     philippaeilhart dhublath hurt eyes ablaze ins...\n",
       "29     accident cleared paturnpike patp eb pa18 cran...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['text'].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('../../Data/NLPNovice/DSKtrain.csv', index=False)\n",
    "test.to_csv('../../Data/NLPNovice/DSKtest.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pre cleaned text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre cleaned text files\n",
    "train = pd.read_csv('../../Data/NLPNovice/DSKtrain.csv')\n",
    "test = pd.read_csv('../../Data/NLPNovice/DSKtest.csv')\n",
    "\n",
    "# Convert text column from object to string\n",
    "train['text'] = train['text'].apply(lambda x : str(x))\n",
    "test['text'] = test['text'].apply(lambda x : str(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Tensor Flow Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hub' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-2800947b44de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodule_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbert_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'hub' is not defined"
     ]
    }
   ],
   "source": [
    "module_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\"\n",
    "bert_layer = hub.KerasLayer(module_url, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_encode(texts, tokenizer, max_len=512):\n",
    "    all_tokens = []\n",
    "    all_masks = []\n",
    "    all_segments = []\n",
    "    \n",
    "    for text in texts:\n",
    "        text = tokenizer.tokenize(text)\n",
    "            \n",
    "        text = text[:max_len-2]\n",
    "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
    "        pad_len = max_len - len(input_sequence)\n",
    "        \n",
    "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
    "        tokens += [0] * pad_len\n",
    "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
    "        segment_ids = [0] * max_len\n",
    "        \n",
    "        all_tokens.append(tokens)\n",
    "        all_masks.append(pad_masks)\n",
    "        all_segments.append(segment_ids)\n",
    "    \n",
    "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = FullTokenizer(vocab_file, do_lower_case)\n",
    "maxlength=130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = bert_encode(train.text.values, tokenizer, max_len=maxlength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = bert_encode(test.text.values, tokenizer, max_len=maxlength)\n",
    "train_labels = train.target.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Tensor Flow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_word_ids (InputLayer)     [(None, 130)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, 130)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 130)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer_4 (KerasLayer)      [(None, 1024), (None 335141889   input_word_ids[0][0]             \n",
      "                                                                 input_mask[0][0]                 \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_3 (Te [(None, 1024)]       0           keras_layer_4[0][1]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            1025        tf_op_layer_strided_slice_3[0][0]\n",
      "==================================================================================================\n",
      "Total params: 335,142,914\n",
      "Trainable params: 335,142,913\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_word_ids = Input(shape=(maxlength,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "input_mask = Input(shape=(maxlength,), dtype=tf.int32, name=\"input_mask\")\n",
    "segment_ids = Input(shape=(maxlength,), dtype=tf.int32, name=\"segment_ids\")\n",
    "\n",
    "_, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids]) \n",
    "\n",
    "clf_output = sequence_output[:, 0, :]\n",
    "\n",
    "out = Dense(1, activation='sigmoid')(clf_output)\n",
    "\n",
    "model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n",
    "\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6090 samples, validate on 1523 samples\n",
      "Epoch 1/3\n",
      " 608/6090 [=>............................] - ETA: 13:26:58 - loss: 0.6980 - accuracy: 0.5760"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-261-42185a04f859>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_input, train_labels,\n",
    "    validation_split=0.2,\n",
    "    epochs=3,\n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(modeltest, train['target'])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()   # clear figure\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=model.predict(modeltest)\n",
    "predict=np.round(predict).astype(int).reshape(3263)\n",
    "sub=pd.DataFrame({'id':test['id'].values.tolist(),'target':predict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict(test_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf_tfidf.predict(test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263,)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 1)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred_GloVe_int.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=pd.DataFrame({'id':test.id, 'target':pred})\n",
    "output.to_csv('../../Data/NLPNovice/DSKsubmission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "0         0       1\n",
       "1         2       1\n",
       "2         3       1\n",
       "3         9       1\n",
       "4        11       1\n",
       "...     ...     ...\n",
       "3258  10861       1\n",
       "3259  10865       1\n",
       "3260  10868       1\n",
       "3261  10874       1\n",
       "3262  10875       1\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "7608    0\n",
       "7609    0\n",
       "7610    0\n",
       "7611    0\n",
       "7612    0\n",
       "Name: target, Length: 7613, dtype: int64"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
